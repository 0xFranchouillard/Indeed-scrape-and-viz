{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.indeed.fr/jobs?q=data+analyst&start=10'\n",
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "else:\n",
    "    print(\"Erreur à la connexion...\\nErreur HTTP :\",response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(['DATA ANALYST POUR LES STATISTIQUES MONETAIRES - H/F',\n  'Data Analyst (ALTERNANCE) H/F',\n  'STAGIAIRE DATA ANALYST H/F',\n  'Data Analyst (F/H)',\n  'Data Analyst Intern',\n  'Analyst Data Quality/Data Gouvernance H/F',\n  'Data Analyst (H/F)',\n  'Game Data analyst (H/F) - Studio 1492',\n  'Data analyst IT -(H/F)',\n  \"Assistant Data Analyst & Chargé d'Etudes Marketing (Stage Juin 2021) - H/F\",\n  'Alternance - Data & BI Analyst F/H/X',\n  'Data Analyst H/F',\n  'Data Analyst F/H',\n  'Stage Data analyst H/F',\n  'Data analyst - études rentabilité-(H/F)'],\n [\"Ce poste est au confluent des compétences d'économiste et de data analyst / data scientist.\\nParticiper, en lien avec d'autres directions de la Banque de France,…\",\n  'Modélisation data science (choix du modèle, tuning du modèle).\\nData Analyst (ALTERNANCE) H/F.\\nData Analyst (ALTERNANCE) H/F.',\n  'Développer, automatiser et mettre à jour les dashboards clients en fonction des demandes internes.\\nDévelopper, automatiser et mettre à jour la segmentation…',\n  \"Idéalement ingénieur de formation, vous justifiez d'une expérience significative (minimum 5 ans) en tant que data analyste.\",\n  '.You are data-driven and feel comfortable with excel/Gsheet to run analysis and build business insights from data.',\n  \"En s'appuyant sur l'état de l'art du marché, des besoins internes des responsables de sources, et les experts data et s'assurer de leur appropriation en interne…\",\n  'Proposer des évolutions afin d’améliorer l’Octroi ou limiter la Fraude.\\nPrésenter les propositions aux différents interlocuteurs et comités avec vos avis…',\n  \"Issu(e) d’une formation supérieure en analyse de données, vous disposez d'une solide expérience professionnelle en tant que Data analyst dans l'univers du…\",\n  'En tant qu’Alternant(e) Data Analyst, vous intégrerez une équipe agile et dynamique, exploitant des technologies autour des Middleware.',\n  \"Vous intègrerez l’équipe « Observatoire Client », composé d'un data analyst et d'un responsable enquêtes.\\nAu sein de la direction Marketing et rattaché au pôle…\",\n  \"Contribuer au monitoring journalier des KPIs Business Paiement, aux analyses et au suivi des plans d'action en cas d’incidents.\",\n  \"Titulaire d'une Licence ou d'un diplôme Bac +4/+5 en école d'ingénieurs ou école de commerce avec spécialisation en data marketing, vous avez déjà une première…\",\n  'Rattaché au Directeur du contrôle de gestion, vous êtes responsable de l’alimentation, l’évolution et le contrôle des sources de données du DataWareHouse de l…',\n  \"En tant que Stagiaire Data Analyst, vous intègrerez une équipe composée d'une dizaine de personnes, majoritairement des data analysts.\",\n  \"En tant qu'Alternant(e) data analyst, vous intégrez l'équipe études rentabilité BDDF (Banque de détail France).\\nPlus qu’un poste, un tremplin.\"],\n ['La Banque de France',\n  'Mutex',\n  'JACADI',\n  'esante.gouv.fr',\n  'Back Market',\n  'Nexton Consulting FR',\n  'Crédit Agricole Consumer Finance',\n  'Ubisoft',\n  'Société Générale',\n  'Showroomprive.com',\n  'Meetic',\n  'Bouygues Telecom',\n  'Générale de téléphone',\n  'Bouygues Telecom',\n  'Société Générale'],\n ['Paris (75)',\n  'Châtillon (92)',\n  'Paris 17e (75)',\n  'Paris (75)',\n  'Paris (75)',\n  'Paris (75)',\n  'Massy (91)',\n  'Montreuil (93)',\n  'Fontenay-sous-Bois (94)',\n  'Saint-Denis (93)',\n  'Paris (75)',\n  'Paris (75)',\n  'Saint-Denis (93)',\n  'Paris (75)',\n  'La Défense (92)'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data_from_result(soup): \n",
    "    jobsNames = []\n",
    "    jobsShortDescriptions = []\n",
    "    companiesNames = []\n",
    "    citiesNames = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        \n",
    "        for jobName in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobsNames.append(jobName['title'])\n",
    "            \n",
    "        for companyName in div.find_all(name='span', attrs={'class':'company'}):\n",
    "            companiesNames.append(companyName.text.strip())\n",
    "            \n",
    "    for cityName in soup.findAll('span', attrs={'class': 'location accessible-contrast-color-location'}):\n",
    "        citiesNames.append(cityName.text)\n",
    "        \n",
    "    for jobShortDescription in soup.findAll('div', attrs={'class': 'summary'}):\n",
    "        jobsShortDescriptions.append(jobShortDescription.text.strip())\n",
    "        \n",
    "    return(jobsNames,jobsShortDescriptions,companiesNames,citiesNames)\n",
    "\n",
    "extract_data_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_jobs_pages(job,div):   \n",
    "    for jobName in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "        job['jobsNames'] = (jobName['title'])\n",
    "            \n",
    "    for companyName in div.find_all(name='span', attrs={'class':'company'}):\n",
    "        job['companiesNames'] = (companyName.text.strip())\n",
    "            \n",
    "    for cityName in soup.findAll(name='span', attrs={'class': 'location accessible-contrast-color-location'}):\n",
    "        job['citiesNames'] = (cityName.text.strip())\n",
    "        \n",
    "    for jobShortDescription in soup.findAll('div', attrs={'class': 'summary'}):\n",
    "        job['jobsShortDescriptions'] = (jobShortDescription.text.strip())\n",
    "        \n",
    "    return(job)\n",
    "\n",
    "def get_jobs_pages_from_result(jobs,soup):\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        job = dict()\n",
    "        job = extract_data_from_jobs_pages(job,div)\n",
    "        jobs.append(job)\n",
    "    return jobs\n",
    "\n",
    "jobs = []\n",
    "df = get_jobs_pages_from_result(jobs,soup)\n",
    "\n",
    "columns = ['jobsNames','companiesNames','citiesNames','jobsShortDescriptions']\n",
    "\n",
    "with open('data.json','w') as fp:\n",
    "    json.dump(df,fp,sort_keys=True,indent=2,ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}